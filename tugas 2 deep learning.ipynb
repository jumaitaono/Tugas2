{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RZC9_mxLB9mD"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import keras,os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "classes = 2"
      ],
      "metadata": {
        "id": "vP7BjjlgepEs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MIvvQmsjeroO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac66b093-5c0e-4f21-bfd6-e124608d38a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive'"
      ],
      "metadata": {
        "id": "umyYrJWKe3FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008aed25-43a2-461f-d3a6-779119d19026"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Give dataset path\n",
        "train_path = '/content/drive/MyDrive/dataset/training'\n",
        "test_path = '/content/drive/MyDrive/dataset/testing'"
      ],
      "metadata": {
        "id": "Hc8MKoVFe8a6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "          '/content/drive/MyDrive/dataset/training',\n",
        "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "        class_mode=\"sparse\")"
      ],
      "metadata": {
        "id": "dtWTaBs4fTOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf98cd4-f453-413c-8a02-f73d25a8ce10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = list(train_generator.class_indices.keys())\n",
        "class_name"
      ],
      "metadata": {
        "id": "YXW7Hloffmat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a92cdb8-be0f-486b-9e04-cfce00ad20fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cars', 'motor']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range= 5,\n",
        "        width_shift_range= 0.1,\n",
        "        height_shift_range= 0.1, \n",
        "        horizontal_flip= True,\n",
        "        fill_mode= \"nearest\")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "          '/content/drive/MyDrive/dataset/testing',\n",
        "        target_size= (IMAGE_SIZE, IMAGE_SIZE), class_mode=\"sparse\")"
      ],
      "metadata": {
        "id": "YnITCPAffris",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7dcccf-f999-44ac-bcbe-8a5eeba64845"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
      ],
      "metadata": {
        "id": "cK8O-UYmf1CB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "BN9OBVIEf5r5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "s86DYdEpf8r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d44189-592f-4248-ee35-b2353c3f4d4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LVERdhnygB1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19257bf-09c8-4107-e909-54ac201b4ee8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 134,268,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "0dV-xCVvgGG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44045e5-5360-4efa-e4bc-3487f60db222"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "oME7tvkIh3Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba4590a-2be1-49cb-bbe5-0347772113a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit_generator(steps_per_epoch=10,generator=train_data, validation_data= test_data, validation_steps=10,epochs=10,callbacks=[checkpoint,early])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAQuKWQ4hXOz",
        "outputId": "45cb2d2d-7ca8-4a09-f397-d7bba0cfe676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-16-c05bb0f6c43c>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist = model.fit_generator(steps_per_epoch=10,generator=train_data, validation_data= test_data, validation_steps=10,epochs=10,callbacks=[checkpoint,early])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 1/10 [==>...........................] - ETA: 12:12 - loss: 0.6932 - accuracy: 0.5312"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4SUmX4h7q-vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = class_name[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "N2HBE9K7vDCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in test_generator:\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        predicted_class, confidence = predict(model, images[i])\n",
        "        actual_class = class_name[int(labels[i])] \n",
        "        plt.title(f\"jenis kendaraan: {actual_class},\\n Prediksi: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "        plt.axis(\"off\")\n",
        "    break"
      ],
      "metadata": {
        "id": "jdSqrJwyvFRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}